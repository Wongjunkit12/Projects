{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85398b33-3b67-4699-bf4f-99fb4dbef6b1",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0b486b\">FIT3181 S2 2023 - ASSIGNMENT 1</span>\n",
    "\n",
    "<font size=\"+1\">Due: <span style=\"color:red\">[11:59pm, 08 September 2023]</span>  (Friday)</font>\n",
    "\n",
    "<font size=\"+1\">**Important note:**</font> This is an **individual** assignment. It contributes **25%** to your final mark. Read the assignment instruction carefully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6046830-b520-4f6f-a08e-bba5ede331fe",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0b486b\">  Student Information</span>\n",
    "***\n",
    "Surname: **Wong**  <br/>\n",
    "Firstname: **Bryan Jun Kit**    <br/>\n",
    "Student ID: **32882424**   <br/>\n",
    "Email: **bwon0018@student.monash.edu**    <br/>\n",
    "Your tutorial time: **Friday 12:00-14:00**    <br/>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce83d4f-48ef-426a-80dd-a03a3aa4ac06",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0b486b\">Instruction</span>\n",
    "\n",
    "This notebook has been prepared for your to complete Assignment 1. The theme of this assignment is about practical machine learning knowledge and skills in deep neural networks, including feedforward and convolutional neural networks. Some sections have been partially completed to help you get\n",
    "started. **The total marks for this notebook is 100**.\n",
    "\n",
    "* Before you start, read the entire notebook carefully once to understand what you need to do. <br/>\n",
    "\n",
    "* For each cell marked with **#YOU ARE REQUIRED TO INSERT YOUR CODES IN THIS CELL** or **INSERT YOUR CODES IN THIS CELL**, there will be places where you **must** supply your own codes when instructed. <br>\n",
    "\n",
    "This assignment contains **three** parts:\n",
    "\n",
    "* Part 1: Questions on theory and knowledge on machine learning and deep learning **[30 points]**\n",
    "* Part 2: Coding assessment on TensorFlow for Deep Neural Networks (DNN) **[30 points]**\n",
    "* Part 3: Coding assessment on TensorFlow for Convolution Neural Networks (CNN) **[40 points]**\n",
    "\n",
    "**Hint**: This assignment was essentially designed based on the lectures and tutorials sessions covered from Week 1 to Week 5. You are strongly recommended to go through these contents thoroughly which might help you to complete this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc31af24-7213-49f5-99b9-669c185735cc",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0b486b\">What to submit</span>\n",
    "\n",
    "This assignment is to be completed individually and submitted to Moodle unit site. **By the due date, you are required to submit one  <span style=\"color:red; font-weight:bold\">single zip file, named xxx_assignment01_solution.zip</span> where `xxx` is your student ID, to the corresponding Assignment (Dropbox) in Moodle**. \n",
    "\n",
    "***For example, if your student ID is <span style=\"color:red; font-weight:bold\">12356</span>, then gather all of your assignment solution to folder, create a zip file named <span style=\"color:red; font-weight:bold\">123456_assignment01_solution.zip</span> and submit this file.***\n",
    "\n",
    "Within this zip folder, you **must** submit the following files:\n",
    "\n",
    "1. **A1_Part1_Solutions.ipynb, A1_Part2_Solutions.ipynb, A1_Part3_Solutions.ipynb**: these are your Python notebook solution source files.\n",
    "2. **A1_Part1_Solutions.html, A1_Part2_Solutions.html, A1_Part3_Solutions.html**: these are the output of your Python notebook solution *exported* in HTML format.\n",
    "3. Any **extra files or folder** needed to complete your assignment (e.g., images used in your answers).\n",
    "\n",
    "**You can run your codes on Google Colab. In this case, you need to capture the screenshots of your Google Colab model training and put in corresponding places in your Jupyter notebooks. You also need to store your trained models to folder <span style=\"color:red; font-weight:bold\">*./models*</span> with recognizable file names (e.g., Part3_Sec3_2_model.h5).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f83e10-3989-4235-a3ef-4cce62a57e39",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0b486b\">Part 1: Theory and Knowledge Questions</span>\n",
    "<div style=\"text-align*: right\"><span style=\"color:red\">[Total marks for this part: 30 points]</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61388bef-2a30-4ecb-ae19-2713b7507936",
   "metadata": {},
   "source": [
    "The first part of this assignment is for you to demonstrate your knowledge in deep learning that you have acquired from the lectures and tutorials materials. Most of the contents in this assignment are drawn from **the lectures and labs from weeks 1 to 2**. Going through these materials before attempting this part is highly recommended.\n",
    "\n",
    "**Numpy** is possibly being used in the following questions. You need to import it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65effb9f-5798-43ae-82f6-71700b5e4728",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3947be-76c2-48ae-9d0d-d44a0565e6dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <span style=\"color:#0b486b\">Question 1.1: Activation Functions</span>\n",
    "Activation function plays an important role in modern Deep NNs. In this question, we will explore some of them to get deeper understanding of their characteristics and their advantages.\n",
    "\n",
    "**(a)** Given the Exponential Linear Unit activation function: $$\\text{ELU}\\left(x\\right)=\\begin{cases}\\alpha\\,(e^x-1) & \\text{if}\\,x<0\\ (\\alpha\\ \\text{is a hyper-parameter})\\\\x & \\text{otherwise}\\end{cases}$$\n",
    "\n",
    "State its output range, find its derivative (show your steps), and plot the activation fuction and its derivative.\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[2 points]</span></div>\n",
    "\n",
    "**(b)** In literature, there are a wide range of activation functions that have been proposed. Do a research and select two (2) activation functions that were not discussed in the lecture (including `ReLU`, `sigmoid`, and `tanh`). For each of the selected activation function, do the following:\n",
    "\n",
    "- Find the research paper which propose the activation function.\n",
    "- Write a brief summary of the author's motivation which leads to the activation function (max 150 words).\n",
    "- Write a brief summary of advantages of the activation function (max 150 words).\n",
    "\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[6 points]</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a4feda-310c-4149-a82c-2c8f99260b5d",
   "metadata": {},
   "source": [
    "*# WRITE YOUR ANSWER HERE*\n",
    "<br><br>\n",
    "**(a)**\n",
    "<br><br>\n",
    "Output range: $(-\\alpha, +\\infty)$\n",
    "<br><br>\n",
    "Derivative of Exponential Linear Unit activation function:\n",
    "<br>\n",
    "$$\n",
    "\\text{When } x < 0 \\text{,}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{ELU}'(x)  &= \\frac{d}{dx} [\\alpha (e^x - 1)]\\\\\n",
    "                                    &= \\alpha [\\frac{d}{dx} (e^x - 1)]\\\\\n",
    "                                    &= \\alpha (e^x)\\\\\n",
    "                                    &= \\alpha e^x\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\text{When } x \\ge 0 \\text{,}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{ELU}'(x)  &= \\frac{d}{dx} (x)\\\\\n",
    "                &= 1\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "Therefore the derivative of Exponential Linear Unit activation function is $$\\text{ELU'}\\left(x\\right)=\\begin{cases}\\alpha e^x & \\text{if}\\,x<0\\ (\\alpha\\ \\text{is a hyper-parameter})\\\\1 & \\text{otherwise}\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7127cb92",
   "metadata": {},
   "source": [
    "### Graph of the Exponential Linear Unit Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df642f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import mathplotlib to plot the graph\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def exponential_linear_unit(x: int, alpha: int) -> int:\n",
    "    \"\"\"\n",
    "    Method used to caculate the output of the Exponential Linear Unit activation function based on input x and alpha.\n",
    "    \"\"\"\n",
    "    return np.where(x < 0, alpha * (np.exp(x) - 1), x)\n",
    "   \n",
    "# Create the numpy array for the x and y axis using linspace for x and the exponential linear unit activation function for the y\n",
    "x_axis = np.linspace(-20, 20)\n",
    "y_axis = exponential_linear_unit(x_axis, 1)\n",
    "\n",
    "# Plot the graph using the given x and y axis.\n",
    "plt.figure(figsize = (10, 5))\n",
    "plt.plot(x_axis, y_axis)\n",
    "# Show plot grid.\n",
    "plt.grid(True)\n",
    "# Create a vertical and horizontal line for the the x and y axis lines respectively at coordinates (0, 0)\n",
    "plt.axvline(0, color = \"black\")\n",
    "plt.axhline(0, color = \"black\")\n",
    "# Label the x and y axis respectively.\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"ELU(x)\")\n",
    "# Add the title to the graph.\n",
    "plt.title(\"Exponential Linear Unit Activation Function\")\n",
    "plt.show()  # Display it when run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd23985e",
   "metadata": {},
   "source": [
    "### Graph of the Derivative of the Exponential Linear Unit Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ec40dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import mathplotlib to plot the graph\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def derivative_exponential_linear_unit(x: int, alpha: int) -> int:\n",
    "    \"\"\"\n",
    "    Method used to caculate the output of the derivative of the Exponential Linear Unit activation function based on input x and alpha.\n",
    "    \"\"\"\n",
    "    return np.where(x < 0, alpha * np.exp(x), 1)\n",
    "   \n",
    "# Create the numpy array for the x and y axis using linspace for x and the derivative of the exponential linear unit activation function for the y\n",
    "x_axis = np.linspace(-20, 20)\n",
    "y_axis = derivative_exponential_linear_unit(x_axis, 1)\n",
    "\n",
    "# Plot the graph using the given x and y axis.\n",
    "plt.figure(figsize = (10, 5))\n",
    "plt.plot(x_axis, y_axis)\n",
    "# Show plot grid.\n",
    "plt.grid(True)\n",
    "# Create a vertical and horizontal line for the the x and y axis lines respectively at coordinates (0, 0)\n",
    "plt.axvline(0, color = \"black\")\n",
    "plt.axhline(0, color = \"black\")\n",
    "# Label the x and y axis respectively.\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"ELU'(x)\")\n",
    "# Add the title to the graph.\n",
    "plt.title(\"Derivative of the Exponential Linear Unit Activation Function\")\n",
    "plt.show()  # Display it when run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d37db1f",
   "metadata": {},
   "source": [
    "**(b)**\n",
    "<br><br>\n",
    "#### Gaussian Error Linear Units (GELUs) (Hendrycks, D., & Gimpel, K. (2016)). https://doi.org/10.48550/arXiv.1606.08415\n",
    "<br><br>\n",
    "$$\\begin{align*}\n",
    "\\text{GELU}(x)  &= x P (X \\le x)\\\\\n",
    "                &= x \\Phi (x)\\\\\n",
    "                &= \\frac{1}{2} (1 + \\text{erf} (\\frac{x}{\\sqrt{2}}))\n",
    "\\end{align*}$$\n",
    "<br><br>\n",
    "**Summary:**\n",
    "<br>\n",
    "The authors were interested in finding a better activation function for deep neural networks that can balance the trade-off between nonlinearity and stochastic regularisation. They noticed that the ReLU activation function, which produces zero for negative inputs, could result in gradient flow and sparse activations as well as overfitting and subpar generalisation. 0verfitting occurs in ReLU due to ReLU setting all negative inputs to zero, which causes the network to memorise noise in the training data. Sparse activities arises due to the vanishing gradient problem, where neurons may always output zero for certain inputs during training, hindering the flow of gradients and slowing down the learning process. Therefore, they suggested using the GELU activation function to produce a smoother and more probabilistic activation.\n",
    "<br><br>\n",
    "(123 words)\n",
    "<br><br><br>\n",
    "**Advantages:**\n",
    "<br>\n",
    "One advantage of GELU is that it approximates the expected value of a stochastic binary unit, which can introduce randomness and diversity to the network. This means that the GELU activation can function as a regulariser to lower the network's variance and enhance its capacity for generalisation, reducing the rate of overfitting which are activation functions like ReLU are known to do.\n",
    "<br>\n",
    "<br>\n",
    "Another advantage of GELU is that they preserve some gradient information for negative inputs. This means that the GELU activation can avoid the problem of dead units that do not learn or update their parameters. Dead units are units that output zero for negative inputs and have zero gradients. The GELU activation function avoids this problem by outputting a non-zero value and gradient for negative inputs, which allows them to participate in learning and optimisation.\n",
    "<br><br>\n",
    "(137 words)\n",
    "<br><br><br>\n",
    "#### Swish (Ramachandran, P., Zoph, B., & Le, Q. V. (2017)). https://doi.org/10.48550/arXiv.1710.05941\n",
    "<br><br>\n",
    "$$\\text{Swish}(x) = x \\cdot \\sigma(x) \\text{, where } \\sigma(x) \\text{ is the sigmoid function}$$\n",
    "<br><br>\n",
    "**Summary:**\n",
    "<br>\n",
    "Swish was developed by the authors in an effort to create a smooth, non-monotonic activation function that can get around some of ReLU's drawbacks, including the dying ReLU issue and the absence of a gradient for negative inputs. The phenomenon known as the \"dying ReLU problem\" occurs when some neurons in a network using the ReLU activation function stop learning and become inactive since their outputs are always zero for any input. Due to the absence of a gradient for negative inputs, the ReLU activation function has a zero derivative for said inputs. This can result in learning being impeded and halted which causes the performance to suffer. Thus, Swish was proposed as an activation function to address these issues.\n",
    "<br><br>\n",
    "(120 words)\n",
    "<br><br><br>\n",
    "**Advantages:**\n",
    "<br>\n",
    "One advantage of Swish is that it is smooth and continuously differentiable, meaning it can help with optimization and gradient propagation. This is because it can avoid the multitude of difficulties plaguing other non-smooth or non-differentiable activation functions such as the vanishing gradient problem. It does this by introducing a tunable parameter that controls the trade-off between linearity and nonlinearity.\n",
    "<br>\n",
    "<br>\n",
    "Another advantage of Swish is its self-gated property, which helps in capturing complex patterns and interactions. It accomplishes this by dynamically changing its shape in response to input. Through this, Swish can learn different behaviors for different input regimes, such as being linear, convex, concave, or sigmoidal. Moreover, it can also help with reducing the number of parameters and layers required in the network, because it can implicitly perform feature selection and dimensionality reduction.\n",
    "<br><br>\n",
    "(134 words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fec190b-a0eb-4398-8fe4-5c846a826e1c",
   "metadata": {},
   "source": [
    "### <span style=\"color:#0b486b\">Question 1.2: Feed-forward neural networks</span>\n",
    "Assume that we feed a data point $x$ with a ground-truth label $y=3$ _(with index starting from 1 as in the lecture)_ to the feed-forward neural network with the ReLU activation function at hidden layers as shown in the following figure:\n",
    "\n",
    "<img src=\"Figures/Q2_P1_S2_2023.png\" width=\"600\" align=\"center\"/>\n",
    "\n",
    "**(a)** What is the numerical value of the latent presentation $h^1(x)$\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1 point]</span></div>\n",
    "\n",
    "**(b)** What is the numerical value of the latent presentation $h^2(x)$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1 point]</span></div> \n",
    "\n",
    "**(c)** What is the numerical value of the logit $h^3(x)$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1 point]</span></div>\n",
    "\n",
    "**(d)** What is the corresonding prediction probabilities $p(x)$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1 point]</span></div> \n",
    "\n",
    "**(e)** What is the predicted class? Is it a correct or incorrect prediction?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1 point]</span></div> \n",
    "\n",
    "**(f)** What is the cross-entropy loss caused by the feed-forward neural network at $(x,y)$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[1 point]</span></div> \n",
    "\n",
    "**(g)** Assume that we are applying the label smoothing technique (i.e.,  [link for main paper](https://papers.nips.cc/paper/2019/file/f1748d6b0fd9d439f71450117eba2725-Paper.pdf) from Goeff Hinton) with $\\alpha = 0.1$. What is the relevant loss caused by the feed-forward neural network at $(x,y)$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[2 point]</span></div> \n",
    "\n",
    "\n",
    "**You need to show both formulas and numerical results for earning full mark. Although it is optional, it is great if you show your numpy code for your computation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5483b37a-ce1e-4974-9e97-e81306a81e0b",
   "metadata": {},
   "source": [
    "*# WRITE YOUR ANSWER HERE*\n",
    "\n",
    "**(a)**\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "z^1(x)  &= (W^1 \\cdot x) + b^1\\\\\n",
    "        &=      \\begin{bmatrix}\n",
    "                (1 \\cdot 1) + (-1 \\cdot -1) + (1 \\cdot 0)\\\\\n",
    "                (1 \\cdot 1) + (-1 \\cdot -1) + (-1 \\cdot 0)\\\\ \n",
    "                (2 \\cdot 1) + (-1 \\cdot -1) + (2 \\cdot 0)\\\\ \n",
    "                (-1 \\cdot 1) + (-2 \\cdot -1) + (1 \\cdot 0) \n",
    "                \\end{bmatrix}\n",
    "                +\n",
    "                \\begin{bmatrix}\n",
    "                1\\\\\n",
    "                0\\\\ \n",
    "                1\\\\ \n",
    "                0 \n",
    "                \\end{bmatrix}\\\\\n",
    "\n",
    "        &=      \\begin{bmatrix}\n",
    "                1 + 1 + 0\\\\\n",
    "                1 + 1 + 0\\\\ \n",
    "                2 + 1 + 0\\\\ \n",
    "                -1 + 2 + 0 \n",
    "                \\end{bmatrix}\n",
    "                +\n",
    "                \\begin{bmatrix}\n",
    "                1\\\\\n",
    "                0\\\\ \n",
    "                1\\\\ \n",
    "                0 \n",
    "                \\end{bmatrix}\\\\\n",
    "\n",
    "        &=      \\begin{bmatrix}\n",
    "                2 + 1\\\\\n",
    "                2 + 0\\\\ \n",
    "                3 + 1\\\\ \n",
    "                1 + 0 \n",
    "                \\end{bmatrix}\\\\\n",
    "\n",
    "        &=      \\begin{bmatrix}\n",
    "                3\\\\\n",
    "                2\\\\ \n",
    "                4\\\\ \n",
    "                1 \n",
    "                \\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "<br>Therefore:<b4>\n",
    "\n",
    "$$\n",
    "\\begin{align*} \n",
    "h^1(x)  &= \\text{ReLU}(z^1(x))\\\\\n",
    "        &=      \\begin{bmatrix}\n",
    "                3\\\\\n",
    "                2\\\\ \n",
    "                4\\\\ \n",
    "                1 \n",
    "                \\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69b0efd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(a) \n",
      " [[3]\n",
      " [2]\n",
      " [4]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "# (a)\n",
    "def relu_activation_function(x):\n",
    "    \"\"\"\n",
    "    Will convert any negative inputs to zero.\n",
    "    Else return the inputted x value if positive.\n",
    "    \"\"\"\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "# Calculate the Weighted sum of the first hidden layer by applying the formula (W * x + b) where W is the weight and b is the bias.\n",
    "# Then apply the ReLU activation function on the result to obtain the numerical value of the first hidden layer.\n",
    "h_1 = relu_activation_function(np.dot(np.matrix([[1, -1, 1], [1, -1, -1], [2, -1, 2], [-1, -2, 1]]), np.matrix([[1], [-1], [0]])) + np.matrix([[1], [0], [1], [0]]))\n",
    "\n",
    "# Output the answer\n",
    "print(\"(a) \\n {0}\".format(h_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e9610e",
   "metadata": {},
   "source": [
    "**(b)**\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "z^2(x)  &= (W^2 \\cdot h^1(x)) + b^2\\\\\n",
    "        &=      \\begin{bmatrix}\n",
    "                (1 \\cdot 3) + (-1 \\cdot 2) + (-1 \\cdot 4) + (2 \\cdot 1)\\\\\n",
    "                (1 \\cdot 3) + (-1 \\cdot 2) + (1 \\cdot 4) + (-1 \\cdot 1)\\\\\n",
    "                (1 \\cdot 3) + (2 \\cdot 2) + (-1 \\cdot 4)  + (2 \\cdot 1)\n",
    "                \\end{bmatrix}\n",
    "                +\n",
    "                \\begin{bmatrix}\n",
    "                -1\\\\\n",
    "                1\\\\ \n",
    "                0 \n",
    "                \\end{bmatrix}\\\\\n",
    "\n",
    "        &=      \\begin{bmatrix}\n",
    "                3 - 2 - 4 + 2\\\\\n",
    "                3 - 2 + 4 - 1\\\\ \n",
    "                3 + 4 - 4 + 2\n",
    "                \\end{bmatrix}\n",
    "                +\n",
    "                \\begin{bmatrix}\n",
    "                -1\\\\\n",
    "                1\\\\ \n",
    "                0 \n",
    "                \\end{bmatrix}\\\\\n",
    "\n",
    "        &=      \\begin{bmatrix}\n",
    "                -1 - 1\\\\\n",
    "                4 + 1\\\\ \n",
    "                5 + 0\n",
    "                \\end{bmatrix}\\\\\n",
    "\n",
    "        &=      \\begin{bmatrix}\n",
    "                -2\\\\\n",
    "                5\\\\ \n",
    "                5\n",
    "                \\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "<br>Therefore:<b4>\n",
    "\n",
    "$$\n",
    "\\begin{align*} \n",
    "h^2(x)  &= \\text{ReLU}(z^2(x))\\\\\n",
    "        &=      \\begin{bmatrix}\n",
    "                0\\\\\n",
    "                5\\\\ \n",
    "                5\n",
    "                \\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "915541ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b) \n",
      " [[0]\n",
      " [5]\n",
      " [5]]\n"
     ]
    }
   ],
   "source": [
    "# (b)\n",
    "# Calculate the Weighted sum of the second hidden layer by applying the formula (W * x + b) where W is the weight and b is the bias.\n",
    "# Then apply the ReLU activation function on the result to obtain the numerical value of the second hidden layer.\n",
    "h_2 = relu_activation_function(np.dot(np.matrix([[1, -1, -1, 2], [1, -1, 1, -1], [1, 2, -1, 2]]), h_1) + np.matrix([[-1], [1], [0]]))\n",
    "\n",
    "# Output the answer\n",
    "print(\"(b) \\n {0}\".format(h_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02358bc6",
   "metadata": {},
   "source": [
    "**(c)**\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "h^3(x)  &= (W^3 \\cdot h^2(x)) + b^3\\\\\n",
    "        &=      \\begin{bmatrix}\n",
    "                (1 \\cdot 0) + (-2 \\cdot 5) + (1 \\cdot 5)\\\\\n",
    "                (1 \\cdot 0) + (2 \\cdot 5) + (-1 \\cdot 5)\\\\\n",
    "                (-1 \\cdot 0) + (1 \\cdot 5) + (-1 \\cdot 5)\n",
    "                \\end{bmatrix}\n",
    "                +\n",
    "                \\begin{bmatrix}\n",
    "                4\\\\\n",
    "                -2\\\\ \n",
    "                2\n",
    "                \\end{bmatrix}\\\\\n",
    "\n",
    "        &=      \\begin{bmatrix}\n",
    "                0 - 10 + 5\\\\\n",
    "                0 + 10 - 5\\\\ \n",
    "                0 + 5 - 5\n",
    "                \\end{bmatrix}\n",
    "                +\n",
    "                \\begin{bmatrix}\n",
    "                4\\\\\n",
    "                -2\\\\ \n",
    "                2\n",
    "                \\end{bmatrix}\\\\\n",
    "\n",
    "        &=      \\begin{bmatrix}\n",
    "                -5 + 4\\\\\n",
    "                5 - 2\\\\ \n",
    "                0 + 2\n",
    "                \\end{bmatrix}\\\\\n",
    "\n",
    "        &=      \\begin{bmatrix}\n",
    "                -1\\\\\n",
    "                3\\\\ \n",
    "                2\n",
    "                \\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed8ce2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(c) \n",
      " [[-1]\n",
      " [ 3]\n",
      " [ 2]]\n"
     ]
    }
   ],
   "source": [
    "# (c)\n",
    "# Calculate the Weighted sum of the third hidden layer by applying the formula (W * x + b) where W is the weight and b is the bias.\n",
    "# As the third hidden layer is the output layer, do not apply the ReLU activation function on it.\n",
    "h_3 = np.dot(np.matrix([[1, -2, 1], [1, 2, -1], [-1, 1, -1]]), h_2) + np.matrix([[4], [-2], [2]])\n",
    "\n",
    "# Output the answer\n",
    "print(\"(c) \\n {0}\".format(h_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2daca917",
   "metadata": {},
   "source": [
    "**(d)**\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "p(x)    &=      softmax (h^3(x))\\\\ \n",
    "\n",
    "        &=      \\begin{bmatrix}\n",
    "                \\frac{e^{-1}}{e^{-1} + e^{3} + e^{2}}\\\\\n",
    "                \\frac{e^{-1}}{e^{-1} + e^{3} + e^{2}}\\\\\n",
    "                \\frac{e^{-1}}{e^{-1} + e^{3} + e^{2}}\n",
    "                \\end{bmatrix}\\\\\n",
    "                \n",
    "        &=      \\begin{bmatrix}\n",
    "                0.01321289\\\\\n",
    "                0.72139918\\\\ \n",
    "                0.26538793 \n",
    "                \\end{bmatrix}\\\\\n",
    "\n",
    "        &\\thickapprox \n",
    "                \\begin{bmatrix}\n",
    "                0.013\\\\\n",
    "                0.721\\\\ \n",
    "                0.265\n",
    "                \\end{bmatrix}\\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5257c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(d) \n",
      " [[0.01321289]\n",
      " [0.72139918]\n",
      " [0.26538793]]\n"
     ]
    }
   ],
   "source": [
    "# Obtain the prediction probabilities p(x) using the softmax function.\n",
    "p = np.exp(h_3) / np.sum(np.exp(h_3))\n",
    "print(\"(d) \\n {0}\".format(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ac1fde",
   "metadata": {},
   "source": [
    "**(e)**\n",
    "The predicted class is class 2 as they have the highest probability of 0.721. However, the ground-truth label is actually class 3. This means the prediction is incorrect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cbce20",
   "metadata": {},
   "source": [
    "**(f)**\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{CE} ([0, 0, 1] \\text{, } p(x))    &= (0 \\cdot \\text{log}(0.01321289)) - (0 \\cdot \\text{log}(0.72139918)) - (1 \\cdot \\text{log}(0.26538793))\\\\\n",
    "                                        &= 0 - 0 - \\text{log}(0.26538793)\\\\\n",
    "                                        &= 1.3265626412674705\\\\\n",
    "                                        &\\thickapprox 1.33\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(f) \n",
      " 1.3265626412674705\n"
     ]
    }
   ],
   "source": [
    "# (f)\n",
    "# The one_hot_vector\n",
    "one_hot_vector = np.array([0, 0, 1])\n",
    "# Calculate cross-entropy loss\n",
    "ce_loss = -np.sum(one_hot_vector * np.log(p))\n",
    "\n",
    "print(\"(f) \\n {0}\".format(ce_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d79edf",
   "metadata": {},
   "source": [
    "**(g)**\n",
    "$$\n",
    "\\begin{align*}\n",
    "y_{\\text{LS}}  &= y \\cdot (1 - \\alpha) + \\frac{\\alpha}{\\text{K}}\\\\\n",
    "                &=      \\begin{bmatrix}\n",
    "                        0\\\\\n",
    "                        0\\\\\n",
    "                        1\n",
    "                        \\end{bmatrix} \\cdot (1 - 0.1) + \\frac{0.1}{3}\\\\\n",
    "                &=      \\begin{bmatrix}\n",
    "                        0\\\\\n",
    "                        0\\\\\n",
    "                        0.9\n",
    "                        \\end{bmatrix} + \\frac{0.1}{3}\\\\\n",
    "                &=      \\begin{bmatrix}\n",
    "                        0.03333333\\\\\n",
    "                        0.03333333\\\\\n",
    "                        0.93333333\n",
    "                        \\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$ \n",
    "\n",
    "<br><br>\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{Relevant Loss}\n",
    "                &= (0.03333333 \\cdot \\text{log}(0.01321289)) - (0.03333333 \\cdot \\text{log}(0.72139918)) - (0.93333333 \\cdot \\text{log}(0.26538793))\\\\\n",
    "                &= 1.3932293079341371\\\\\n",
    "                &\\thickapprox 1.39\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f9cb302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(g) \n",
      " 1.3932293079341371\n"
     ]
    }
   ],
   "source": [
    "# (g)\n",
    "def label_smooth_function(y, alpha: int, K: int):\n",
    "    \"\"\"\n",
    "    Formula for Label Smooth Technique using the formula y * (1 - alpha) + (alpha / K)\n",
    "    \"\"\"\n",
    "    # The one_hot_vector.\n",
    "    one_hot_vector = np.array([0, 0, 0])\n",
    "    one_hot_vector[K - 1] = 1\n",
    "    # Calculate the label_smooth result using the formula given.\n",
    "    result = ((1 - alpha) * one_hot_vector) + (alpha / K)\n",
    "\n",
    "    return result\n",
    "\n",
    "# Calculate the relevant loss using the label smooth technique.\n",
    "relevant_loss = -np.sum(label_smooth_function(one_hot_vector, 0.1, 3) * np.log(p))\n",
    "\n",
    "print(\"(g) \\n {0}\".format(relevant_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06086408-96f0-4871-8827-0e3e2a5d0937",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <span style=\"color:#0b486b\">Question 1.3: Back propagation</span>\n",
    "Assume that we are constructing a multilayered feed-forward neural network for a classification problem with three classes where the model parameters will be generated randomly using your student ID. \n",
    "\n",
    "The architecture is as follows: $3 (Input)\\rightarrow4(LeakyReLU)\\rightarrow 3(Output)$ (see figure below). Also note that the model parameters are randomly generated.\n",
    "\n",
    "<img src=\"Figures/Q3_P1_S2_2023.png\" width=\"500\" align=\"center\"/>\n",
    "\n",
    "We then feed a feature vector $x=\\left[\\begin{array}{ccc} 1 & -1 & 0\\end{array}\\right]^{T}$ with ground-truth label $y=3$ to the above network.\n",
    "\n",
    "**You need to show both formulas, numerical results, and your numpy code for your computation for earning full marks.**\n",
    "\n",
    "**(a)** Suppose that we use the cross-entropy (CE) loss. What is the value of the CE loss $l$?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[2 point]</span></div>\n",
    "\n",
    "**(b)** What are the derivatives $\\frac{\\partial l}{\\partial h^{2}},\\frac{\\partial l}{\\partial W^{2}}$, and $\\frac{\\partial l}{\\partial b^{2}}$\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[3 points]</span></div>\n",
    "\n",
    "**(c)** What are the derivatives $\\frac{\\partial l}{\\partial h^{1}}, \\frac{\\partial l}{\\partial \\bar{h}^{1}},\\frac{\\partial l}{\\partial W^{1}}$, and $\\frac{\\partial l}{\\partial b^{1}}$? \n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[3 points]</span></div>\n",
    "\n",
    "**(d)** Assume that we use SGD with learning rate $\\eta=0.01$ to update the model parameters. What are the values of $W^2, b^2$ and $W^1, b^1$ after updating?\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[2 points]</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818e7163",
   "metadata": {},
   "source": [
    "**(a)**\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "z^1(x)  &=      (W^1 \\cdot x) + b^1\\\\\n",
    "        &=      \\begin{bmatrix}\n",
    "                (0.62497325 \\cdot 1) + (-0.22092984 \\cdot -1) + (-0.82545474 \\cdot 0)\\\\\n",
    "                (-1.7699437  \\cdot 1) + (0.18893564 \\cdot -1) + (0.7134674 \\cdot 0)\\\\ \n",
    "                (0.82714877 \\cdot 1) + (-0.64887739 \\cdot -1) + (0.83694064 \\cdot 0)\\\\ \n",
    "                (-1.05206796 \\cdot 1) + (-1.94660144 \\cdot -1) + (2.39934532 \\cdot 0) \n",
    "                \\end{bmatrix}\n",
    "                +\n",
    "                \\begin{bmatrix}\n",
    "                -0.07911797\\\\\n",
    "                0.05735999\\\\ \n",
    "                -0.5102699\\\\ \n",
    "                -1.37969533 \n",
    "                \\end{bmatrix}\\\\\n",
    "\n",
    "        &=      \\begin{bmatrix}\n",
    "                0.62497325 + 0.22092984 + 0\\\\\n",
    "                -1.7699437 - 0.18893564 + 0\\\\ \n",
    "                0.82714877 + 0.64887739 + 0\\\\ \n",
    "                -1.05206796 + 1.94660144 + 0 \n",
    "                \\end{bmatrix}\n",
    "                +\n",
    "                \\begin{bmatrix}\n",
    "                -0.07911797\\\\\n",
    "                0.05735999\\\\ \n",
    "                -0.5102699\\\\ \n",
    "                -1.37969533 \n",
    "                \\end{bmatrix}\\\\\n",
    "\n",
    "        &=      \\begin{bmatrix}\n",
    "                0.84590308 - 0.07911797\\\\\n",
    "                -1.95887935 + 0.05735999\\\\ \n",
    "                1.47602616 - 0.5102699\\\\ \n",
    "                0.89453348 - 1.37969533\n",
    "                \\end{bmatrix}\\\\\n",
    "\n",
    "        &=      \\begin{bmatrix}\n",
    "                0.76678511\\\\\n",
    "                -1.90151936\\\\ \n",
    "                0.96575626\\\\ \n",
    "                -0.48516185 \n",
    "                \\end{bmatrix}\\\\\\\\\n",
    "\n",
    "h^1(x)  &= \\text{Leaky ReLU}(z^1(x))\\\\\n",
    "        &=      \\begin{bmatrix}\n",
    "                0.76678511\\\\\n",
    "                -0.01901519\\\\ \n",
    "                0.96575626\\\\ \n",
    "                -0.00485162 \n",
    "                \\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "<br><br>\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "h^2(x)  &=      (W^2 \\cdot h^1(x)) + b^2\\\\\n",
    "        &=      \\begin{bmatrix}\n",
    "                (0.21703338 \\cdot 0.76678511) + (-0.18881434 \\cdot -0.01901519) + (1.21779488 \\cdot 0.96575626) + (-0.35724098 \\cdot -0.00485162)\\\\\n",
    "                (0.92656842 \\cdot 0.76678511) + (-0.00776975 \\cdot -0.01901519) + (0.63916736 \\cdot 0.96575626) + (-0.54400342 \\cdot -0.00485162)\\\\\n",
    "                (0.09965436 \\cdot 0.76678511) + (1.14840463 \\cdot -0.01901519) + (0.32915445 \\cdot 0.96575626) + (-0.96068978 \\cdot -0.00485162)\n",
    "                \\end{bmatrix}\n",
    "                +\n",
    "                \\begin{bmatrix}\n",
    "                1.73720173\\\\\n",
    "                -1.02837722\\\\ \n",
    "                0.71463634\n",
    "                \\end{bmatrix}\\\\\n",
    "\n",
    "        &=      \\begin{bmatrix}\n",
    "                1.34783454 + 1.73720173\\\\\n",
    "                1.33054579 - 1.028377222\\\\ \n",
    "                0.37712021 + 0.71463634\n",
    "                \\end{bmatrix}\\\\\n",
    "\n",
    "        &=      \\begin{bmatrix}\n",
    "                3.08503627\\\\\n",
    "                0.30216857\\\\ \n",
    "                1.09175656\n",
    "                \\end{bmatrix}\\\\\\\\\n",
    "\n",
    "p(x)    &=      softmax (h^2(x))\\\\ \n",
    "\n",
    "        &=      \\begin{bmatrix}\n",
    "                \\frac{e^{3.08503627}}{e^{3.08503627} + e^{0.30216857} + e^{1.09175656}}\\\\\n",
    "                \\frac{e^{3.08503627}}{e^{3.08503627} + e^{0.30216857} + e^{1.09175656}}\\\\\n",
    "                \\frac{e^{3.08503627}}{e^{3.08503627} + e^{0.30216857} + e^{1.09175656}}\n",
    "                \\end{bmatrix}\\\\\n",
    "                \n",
    "        &=      \\begin{bmatrix}\n",
    "                0.83464881\\\\\n",
    "                0.05163209\\\\ \n",
    "                0.1137191\n",
    "                \\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "<br><br>\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{CE} ([0, 0, 1] \\text{, } p(x))    &= (0 \\cdot \\text{log}(0.83464881)) - (0 \\cdot \\text{log}(0.05163209)) - (1 \\cdot \\text{log}(0.1137191))\\\\\n",
    "                                        &= 0 - 0 - \\text{log}(0.1137191)\\\\\n",
    "                                        &= 2.1740239365947516\\\\\n",
    "                                        &\\thickapprox 2.17\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68fae312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(a) \n",
      " 2.1740239365947516\n"
     ]
    }
   ],
   "source": [
    "# (a)\n",
    "def leaky_relu_function(x):\n",
    "    \"\"\"\n",
    "    Leaky ReLU Activation Function.\n",
    "    \"\"\"\n",
    "    # Return alpha * x or x.\n",
    "    return np.maximum(0.01 * x, x)\n",
    "\n",
    "def forward_propogation(x, w, b):\n",
    "    \"\"\"\n",
    "    Forward propogation through the deep neural network.\n",
    "    Will progress from one hidden layer to the next by applying the formula.\n",
    "    \"\"\"\n",
    "    # Return the result of the dot product of weight and x + bias to calculate the numerical value of the hidden layer.\n",
    "    return np.dot(w, x) + b\n",
    "\n",
    "def softmax_function(x):\n",
    "    \"\"\"\n",
    "    Calculate the probabilities p(x) using the softmax function formula and input x.\n",
    "    \"\"\"\n",
    "    # Return the probabilities of each category.\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "def cross_entropy_loss(y, p):\n",
    "    \"\"\"\n",
    "    Calculate the cross entropy loss by using the one_hot_vector and p values. \n",
    "    \"\"\"\n",
    "    # Determine the one hot values using the inputted p.\n",
    "    one_hot_vector = np.zeros_like(p)     # Create a matrix of zeroes same size as p.\n",
    "    one_hot_vector[y - 1] = 1             # Set y - 1 to one.    \n",
    "    \n",
    "    # Return the cross entropy loss.\n",
    "    return -np.sum(one_hot_vector * np.log(p)), one_hot_vector\n",
    "\n",
    "# Use student ID as the random seed.\n",
    "np.random.seed(32882424)\n",
    "# Generate random weights and biases for each layer using the student ID as the random seed.\n",
    "w_1 = np.random.randn(4, 3)\n",
    "b_1 = np.random.randn(4, 1)\n",
    "w_2 = np.random.randn(3, 4)\n",
    "b_2 = np.random.randn(3, 1)\n",
    "\n",
    "# Initialise x and y variables (input feature vector and ground-truth label based on values given).\n",
    "x = np.array([[1], [-1], [0]])\n",
    "y = 3\n",
    "\n",
    "# Calculate the numerical value of the first hidden layer before and after running through the Leaky ReLU activation function.\n",
    "z_1 = forward_propogation(x, w_1, b_1)\n",
    "h_1 = leaky_relu_function(z_1)\n",
    "\n",
    "# Calculate the numerical value of the output layer\n",
    "h_2 = forward_propogation(h_1, w_2, b_2)\n",
    "# Calculate the softmax probabilities p(x).\n",
    "p = softmax_function(h_2)\n",
    "\n",
    "# Calculate the cross-entropy loss\n",
    "ce_loss, one_hot_vector = cross_entropy_loss(y, p)\n",
    "print(\"(a) \\n {0}\".format(ce_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e04e20",
   "metadata": {},
   "source": [
    "**(b)**\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "h^2 &= W^2 \\cdot h^1 + b^2\\\\\\\\\n",
    "\\frac{\\partial l}{\\partial h^{2}}   &=  g^2\\\\\n",
    "                                    &=  -1_y + \\text{softmax}(h^3)\\\\\n",
    "                                    &=  p - 1_y\\\\\n",
    "                                    &=  \\begin{bmatrix}\n",
    "                                        0.83464881\\\\\n",
    "                                        0.05163209\\\\\n",
    "                                        0.1137191\n",
    "                                        \\end{bmatrix} - \n",
    "                                        \\begin{bmatrix}\n",
    "                                        0\\\\\n",
    "                                        0\\\\\n",
    "                                        1\n",
    "                                        \\end{bmatrix}\\\\\n",
    "                                    &=  \\begin{bmatrix}\n",
    "                                        0.83464881\\\\\n",
    "                                        0.05163209\\\\\n",
    "                                        -0.8862809\n",
    "                                        \\end{bmatrix}\\\\\\\\\n",
    "                                        \n",
    "\\frac{\\partial l}{\\partial W^2} &=  \\frac{\\partial l}{\\partial h^2} \\cdot \\frac{\\partial h^2}{\\partial W^2}\\\\\n",
    "                                &=  (g^2)^T \\cdot (h^1)^T\\\\\n",
    "                                &=  \\\\\\\\\n",
    "\n",
    "\\frac{\\partial l}{\\partial b^2} &=  \\frac{\\partial l}{\\partial h^2} \\cdot \\frac{\\partial h^2}{\\partial b^2}\\\\\n",
    "                                &=  (g^2)^T\\\\\n",
    "                                &=  \\begin{bmatrix}\n",
    "                                    0.83464881\\\\\n",
    "                                    0.05163209\\\\\n",
    "                                    -0.8862809\n",
    "                                    \\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a37482bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b) \n",
      " Derivative of l with respect to h2: \n",
      "[[ 0.83464881]\n",
      " [ 0.05163209]\n",
      " [-0.8862809 ]]\n",
      "Derivative of l with respect to w2: \n",
      "[[ 6.39996283e-01 -1.58710088e-02  8.06067320e-01 -4.04939760e-03]\n",
      " [ 3.95907168e-02 -9.81794162e-04  4.98640131e-02 -2.50499195e-04]\n",
      " [-6.79587000e-01  1.68528029e-02 -8.55931333e-01  4.29989679e-03]]\n",
      "Derivative of l with respect to b2: \n",
      "[[ 0.83464881]\n",
      " [ 0.05163209]\n",
      " [-0.8862809 ]]\n"
     ]
    }
   ],
   "source": [
    "# (b)\n",
    "# Calculate the derivative of loss with respect to h2 using the formula given above.\n",
    "# p - 1_y where 1_y is the one-hot vector\n",
    "dl_dh2 = p - one_hot_vector\n",
    "print(\"(b) \\n Derivative of l with respect to h2: \\n{0}\".format(dl_dh2))\n",
    "\n",
    "# Calculate the derivative of loss with respect to w2 using the formula given above.\n",
    "dl_dw2 = np.dot(dl_dh2, h_1.T)\n",
    "print(\"Derivative of l with respect to w2: \\n{0}\".format(dl_dw2))\n",
    "\n",
    "# Calculate the derivative of loss with respect to b2.\n",
    "dl_db2 = dl_dh2\n",
    "print(\"Derivative of l with respect to b2: \\n{0}\".format(dl_db2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e4dc6c",
   "metadata": {},
   "source": [
    "**(c)**\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\bar h^1 &= W^1 \\cdot x + b^1\\\\\\\\\n",
    "\\frac{\\partial l}{\\partial h^{1}}   &=  g^1\\\\\n",
    "                                    &=  \\frac{\\partial l}{\\partial h^2} \\cdot \\frac{\\partial h^2}{\\partial h^1}\\\\\n",
    "                                    &=  g^2 \\cdot W^2\\\\\n",
    "                                    &=  \\begin{bmatrix}\n",
    "                                        0.14066556\\\\\n",
    "                                        -1.17580392\\\\\n",
    "                                        0.7577093\\\\\n",
    "                                        0.52518221\n",
    "                                        \\end{bmatrix}\\\\\\\\\n",
    "  \n",
    "\\frac{\\partial l}{\\partial W^1} &=  \\frac{\\partial l}{\\partial \\bar h^1} \\cdot \\frac{\\partial \\bar h^1}{\\partial W^1}\\\\\n",
    "                                &=  (\\bar g^1)^T \\cdot (x)^T\\\\\n",
    "                                &=  \\begin{bmatrix}\n",
    "                                    0.14066556 & -0.14066556 & 0\\\\\n",
    "                                    -0.01175804 & 0.01175804 & 0\\\\\n",
    "                                    0.7577093 & -0.7577093 & 0\\\\\n",
    "                                    0.00525182 & -0.00525182 & 0\n",
    "                                    \\end{bmatrix}\\\\\\\\\n",
    "\n",
    "\\frac{\\partial l}{\\partial b^1} &=  \\frac{\\partial l}{\\partial \\bar h^1} \\cdot \\frac{\\partial \\bar h^1}{\\partial b^1}\\\\\n",
    "                                &=  (\\bar g^2)^T\\\\\n",
    "                                &=  \\begin{bmatrix}\n",
    "                                    0.14066556\\\\\n",
    "                                    -0.01175804\\\\\n",
    "                                    0.7577093\\\\\n",
    "                                    0.00525182\n",
    "                                    \\end{bmatrix}\\\\\\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5eae291f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(c) \n",
      " Derivative of l with respect to h1: \n",
      "[[ 0.14066556]\n",
      " [-1.17580392]\n",
      " [ 0.7577093 ]\n",
      " [ 0.52518221]]\n",
      "Derivative of l with respect to w1: \n",
      "[[ 0.14066556 -0.14066556  0.        ]\n",
      " [-0.01175804  0.01175804 -0.        ]\n",
      " [ 0.7577093  -0.7577093   0.        ]\n",
      " [ 0.00525182 -0.00525182  0.        ]]\n",
      "Derivative of l with respect to b1: \n",
      "[[ 0.14066556]\n",
      " [-0.01175804]\n",
      " [ 0.7577093 ]\n",
      " [ 0.00525182]]\n"
     ]
    }
   ],
   "source": [
    "# (c)\n",
    "def derivative_leaky_relu(x):\n",
    "    \"\"\"\n",
    "    Derivative of the Leaky ReLU Activation Function.\n",
    "    \"\"\"\n",
    "    # Return the pre-activation function values of the hidden layer.\n",
    "    return np.where(x > 0, 1, 0.01)\n",
    "\n",
    "# Calculate the derivative of loss with respect to h1 using the formula given above.\n",
    "dl_dh1 = np.dot(w_2.T, dl_dh2)\n",
    "print(\"(c) \\n Derivative of l with respect to h1: \\n{0}\".format(dl_dh1))\n",
    "\n",
    "# Calculate the derivative of loss with respect to the h1 values before the Leaky ReLU activation function.\n",
    "dl_bar_dh1 = derivative_leaky_relu(z_1) * dl_dh1\n",
    "\n",
    "# Calculate the derivative of loss with respect to the w1 based on the formula given above.\n",
    "dl_dw1 = np.dot(dl_bar_dh1, x.T)\n",
    "print(\"Derivative of l with respect to w1: \\n{0}\".format(dl_dw1))\n",
    "\n",
    "# Calculate the derivative of loss with respect to the b1 based on the formula given above.\n",
    "dl_db1 = dl_bar_dh1\n",
    "print(\"Derivative of l with respect to b1: \\n{0}\".format(dl_db1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dac944",
   "metadata": {},
   "source": [
    "**(d)**\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e2027d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated W2 with learning rate 0.01: \n",
      "[[ 0.21063342 -0.18865563  1.20973421 -0.35720049]\n",
      " [ 0.92617251 -0.00775993  0.63866872 -0.54400092]\n",
      " [ 0.10645023  1.1482361   0.33771376 -0.96073278]]\n",
      "Updated b2 with learning rate 0.01: \n",
      "[[ 1.72885525]\n",
      " [-1.02889354]\n",
      " [ 0.72349915]]\n",
      "Updated W1 with learning rate 0.01: \n",
      "[[ 0.62356659 -0.21952318 -0.82545474]\n",
      " [-1.76982612  0.18881806  0.7134674 ]\n",
      " [ 0.81957168 -0.6413003   0.83694064]\n",
      " [-1.05212048 -1.94654892  2.39934532]]\n",
      "Updated b1 with learning rate 0.01: \n",
      "[[-0.08052463]\n",
      " [ 0.05747757]\n",
      " [-0.517847  ]\n",
      " [-1.37974785]]\n"
     ]
    }
   ],
   "source": [
    "# (d)\n",
    "# The learning rate eta set to 0.01\n",
    "eta = 0.01\n",
    "\n",
    "# Calculate the new updated W2, b2, W1, b1\n",
    "eta_w2 = w_2 - (dl_dw2 * eta)\n",
    "eta_b2 = b_2 - (dl_db2 * eta)\n",
    "eta_w1 = w_1 - (dl_dw1 * eta)\n",
    "eta_b1 = b_1 - (dl_db1 * eta)\n",
    "\n",
    "print(\"Updated W2 with learning rate 0.01: \\n{0}\".format(eta_w2))\n",
    "print(\"Updated b2 with learning rate 0.01: \\n{0}\".format(eta_b2))\n",
    "print(\"Updated W1 with learning rate 0.01: \\n{0}\".format(eta_w1))\n",
    "print(\"Updated b1 with learning rate 0.01: \\n{0}\".format(eta_b1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f5a6f6-0a8f-498d-ad06-a2d1063d214f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <span style=\"color:#0b486b\">Question 1.4: Optimization with gradient descent</span>\n",
    "In this question, we will take a step further to get deeper understanding about gradient descent, one of the most important optimization techniques in deep learning.\n",
    "\n",
    "**(a)** Write the pseudo-code to implement the gradient descent algorithm and explain in your words what each line of the code does.\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[2 point]</span></div>\n",
    "\n",
    "**(b)** Explain in your own words why we should update the parameters in the opposite direction of the gradient.\n",
    "<div style=\"text-align: right\"><span style=\"color:red\">[2 points]</span></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615c2297-0d25-4849-9776-2359778ef39b",
   "metadata": {},
   "source": [
    "*# WRITE YOUR ANSWER HERE*\n",
    "\n",
    "**(a)**\n",
    "<br>\n",
    "\\# Initialise the weight and bias parameters randomly\n",
    "w, b = random()\n",
    "\n",
    "\\# Set the learning rate (eta)\n",
    "eta = 0.01\n",
    "\\# Set the number of maximmum iterations for training the model\n",
    "maximum_iterations = 1000\n",
    "\n",
    "for t = 0 up to maximum_iterations:\n",
    "    \\# Forward propagate and compute the gradient of the loss function with respect to w and b.\n",
    "    \\# Backward propogate.\n",
    "    \\# Update the w and b parameters based on its gradient and eta.\n",
    "\n",
    "Explanation:\n",
    "Initialise the weight and bias of the model randomly. Then, set the learning rate (eta). Set the number of times (maximum_iterations) the parameters of the model will be updated during the training process. Forward propogation is performed during each iteration to compute the predicted output of the model based on the parameters. Then, the loss is calculated based on the predicted output and the ground truth label. Back propogation is then done to compute the gradients of the loss with respect to the model's weights and biases. Finally, update the parameters by subtracting eta of the gradient loss function with respect to the weight and bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03bdd66",
   "metadata": {},
   "source": [
    "**(b)**\n",
    "<br>\n",
    "The parameters are updated in the opposite direction of the gradient because we want to minimise the loss function. This is because the gradient represents the direction of the steepest increase. Updating the parameters in the direction of the gradient (during forward propogation) will result in the loss function being maximised, which is not desired. Hence, the parameters are updated in the opposite direction of the gradient, in order to move closer to the local minimum of the loss function. This will result in the minimisation of the loss function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
